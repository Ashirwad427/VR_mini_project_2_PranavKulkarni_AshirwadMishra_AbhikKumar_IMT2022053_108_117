{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1683955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Cell: Load & Strip ID Columns ──────────────────────────────────────────\n",
    "import pandas as pd\n",
    "import os\n",
    "# File paths\n",
    "QA_PATH       = \"Curated_VQA_Dataset_1.csv\"\n",
    "CURATION_PATH = \"Data_Curation_1.csv\"\n",
    "BASE_PATH     = \"/kaggle/input/abo-small/images/small\"\n",
    "# Load both DataFrames as strings\n",
    "qa_df      = pd.read_csv(QA_PATH,       dtype=str)\n",
    "curation_df = pd.read_csv(CURATION_PATH, dtype=str)\n",
    "\n",
    "# Strip whitespace from the ID column in each\n",
    "qa_df[\"main_image_id\"]      = qa_df[\"main_image_id\"].str.strip()\n",
    "curation_df[\"main_image_id\"] = curation_df[\"main_image_id\"].str.strip()\n",
    "\n",
    "# (Optional) Verify\n",
    "# display(qa_df[\"main_image_id\"].head())\n",
    "# display(curation_df[\"main_image_id\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d064f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       main_image_id                             question        answer  \\\n",
       "0       810CTv64h2L            What color are the packs?         White   \n",
       "1       810CTv64h2L        What type of product is this?       Laundry   \n",
       "2       810CTv64h2L                      How many packs?            50   \n",
       "3       810CTv64h2L                   What is the scent?     Unscented   \n",
       "4       810CTv64h2L       What is the container's shape?           Bag   \n",
       "...             ...                                  ...           ...   \n",
       "93726   91L8i6XyTSL           What type of item is this?           Bag   \n",
       "93727   91L8i6XyTSL  What type of attachment is visible?         Strap   \n",
       "93728   91L8i6XyTSL  What type of attachment is visible?         Strap   \n",
       "93729   91L8i6XyTSL               What brand is visible?  AmazonBasics   \n",
       "93730   91L8i6XyTSL               What brand is visible?  AmazonBasics   \n",
       "\n",
       "      used_metadata       image_path  \n",
       "0             False  ae/ae638076.jpg  \n",
       "1              True  ae/ae638076.jpg  \n",
       "2             False  ae/ae638076.jpg  \n",
       "3              True  ae/ae638076.jpg  \n",
       "4             False  ae/ae638076.jpg  \n",
       "...             ...              ...  \n",
       "93726          True  d3/d3a1659f.jpg  \n",
       "93727         False  d3/d3a1659f.jpg  \n",
       "93728         False  d3/d3a1659f.jpg  \n",
       "93729          True  d3/d3a1659f.jpg  \n",
       "93730          True  d3/d3a1659f.jpg  \n",
       "\n",
       "[93731 rows x 5 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Merge on actual 'path' column in cur_df\n",
    "blip_vqa_df = qa_df.merge(\n",
    "    curation_df[[\"main_image_id\", \"path\"]],\n",
    "    on=\"main_image_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 4) Build a full filesystem path column\n",
    "blip_vqa_df[\"image_path\"] = blip_vqa_df[\"path\"]\n",
    "\n",
    "# 5) Drop the intermediate 'path' column\n",
    "blip_vqa_df.drop(columns=[\"path\"], inplace=True)\n",
    "\n",
    "# Preview\n",
    "blip_vqa_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a469cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19436"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blip_vqa_df['main_image_id'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e8ed529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 74975 rows, 15548 images\n",
      "Val   set: 9384 rows, 1944 images\n",
      "Test  set: 9372 rows, 1944 images\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell: Split blip_vqa_df into 80/10/10 train/val/test by image ─────────────────────────\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# assume blip_vqa_df is already loaded in the notebook and contains a 'main_image_id' column\n",
    "\n",
    "# 1) First split: 80% train, 20% temp (val+test)\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, temp_idx = next(\n",
    "    gss.split(blip_vqa_df, groups=blip_vqa_df[\"main_image_id\"])\n",
    ")\n",
    "train_df = blip_vqa_df.iloc[train_idx].reset_index(drop=True)\n",
    "temp_df  = blip_vqa_df.iloc[temp_idx].reset_index(drop=True)\n",
    "\n",
    "# 2) Second split: split temp_df into 50% val / 50% test → each 10% of original\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "val_idx, test_idx = next(\n",
    "    gss2.split(temp_df, groups=temp_df[\"main_image_id\"])\n",
    ")\n",
    "val_df  = temp_df.iloc[val_idx].reset_index(drop=True)\n",
    "test_df = temp_df.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "# 3) Export to CSV for later use\n",
    "train_df.to_csv(\"blip_vqa_train.csv\", index=False)\n",
    "val_df.to_csv(\"blip_vqa_val.csv\",   index=False)\n",
    "test_df.to_csv(\"blip_vqa_test.csv\",  index=False)\n",
    "\n",
    "# 4) Sanity check\n",
    "print(f\"Train set: {train_df.shape[0]} rows, {train_df['main_image_id'].nunique()} images\")\n",
    "print(f\"Val   set: {val_df.shape[0]} rows, {val_df['main_image_id'].nunique()} images\")\n",
    "print(f\"Test  set: {test_df.shape[0]} rows, {test_df['main_image_id'].nunique()} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213f154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
